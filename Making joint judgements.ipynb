{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riri/.virtualenvs/analysis3/lib/python3.4/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/riri/.virtualenvs/analysis3/lib/python3.4/site-packages/sklearn/qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas\n",
    "import pandas.io.sql\n",
    "import tqdm\n",
    "from sklearn import *\n",
    "import ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CategoricalMeanEstimator:\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "        self.cls = None\n",
    "        self.global_mean = None\n",
    "    def fit(self, X, y):\n",
    "        self.cls_mean = y.groupby(X[self.col]).mean().to_frame('estimate_mean')\n",
    "        self.global_mean = y.mean()\n",
    "        \n",
    "        self.cls_median = y.groupby(X[self.col]).median().to_frame('estimate_median')\n",
    "        self.global_median = y.median()\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        x = X[self.col].to_frame('col')\n",
    "        res_mean = pandas.merge(x, self.cls_mean, left_on='col', right_index=True, how='left')\n",
    "        res_median = pandas.merge(x, self.cls_median, left_on='col', right_index=True, how='left')\n",
    "        return (res_mean.estimate_mean.fillna(self.global_mean),\n",
    "                res_median.estimate_median.fillna(self.global_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiCategoricalMeanEstimator:\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        self.cls = None\n",
    "        self.global_mean = None\n",
    "    def fit(self, X, y):\n",
    "        groups = [X[col] for col in self.cols]\n",
    "        self.cls = y.groupby(groups).median().to_frame('estimate').reset_index()\n",
    "        self.global_mean = y.median()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        x = X[self.cols]\n",
    "        res = pandas.merge(\n",
    "            x, self.cls, \n",
    "            left_on=self.cols, right_on=self.cols, \n",
    "            how='left')\n",
    "        return res.fillna(self.global_mean).estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "con = sqlite3.connect('/tmp/data.sqlite3')\n",
    "total = 53364883\n",
    "data = None\n",
    "chunksize = int(5e6)\n",
    "try:\n",
    "    data_iter = pandas.read_sql('''\n",
    "        SELECT week_num,\n",
    "               sales_depo,\n",
    "               sales_channel,\n",
    "               route_id,\n",
    "               client_id,\n",
    "               product_id,\n",
    "               adjusted_demand,\n",
    "               rand\n",
    "          FROM data \n",
    "         WHERE adjusted_demand is not null \n",
    "               AND week_num < 8''', con=con, chunksize=chunksize)\n",
    "    for f in tqdm.tqdm(data_iter, total=1+total//chunksize):\n",
    "        # This halves the memory use :(\n",
    "        for col in f:\n",
    "            if f[col].dtype == np.int64:\n",
    "                f[col] = f[col].astype(np.int32)\n",
    "        if data is None:\n",
    "            data = f\n",
    "        else:\n",
    "            data = pandas.concat([data, f])\n",
    "finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "series = {'adjusted_demand': data.adjusted_demand}\n",
    "admissible_cols = ['week_num', 'sales_depo', 'sales_channel', 'route_id', 'client_id', 'product_id']\n",
    "\n",
    "estimators = {}\n",
    "for col in tqdm.tqdm(admissible_cols):\n",
    "    est = CategoricalMeanEstimator(col)\n",
    "    est.fit(data, data.adjusted_demand)\n",
    "    estimators[col] = est\n",
    "    mean_est, med_est = est.predict(data)\n",
    "    series[col + '_mean'] = mean_est\n",
    "    series[col + '_median'] = med_est\n",
    "    series[col] = data[col]\n",
    "\n",
    "'''\n",
    "if False:\n",
    "    for c1, c2 in tqdm.tqdm([(c1, c2) for c1 in admissible_cols for c2 in admissible_cols if c1 != c2]):\n",
    "        est = MultiCategoricalMeanEstimator([c1, c2])\n",
    "        est.fit(data, data.adjusted_demand)\n",
    "        series_name = c1 + '_' + c2\n",
    "        series[series_name] = est.predict(data)\n",
    "        test_series[series_name] = est.predict(test_data)\n",
    "        del est\n",
    "'''\n",
    "    \n",
    "train_X = pandas.DataFrame(series)\n",
    "train_X['rand'] = data.rand\n",
    "train_X['week_num'] = data.week_num\n",
    "train_X['adjusted_demand'] = data.adjusted_demand\n",
    "del series, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjusted_demand</th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_id_mean</th>\n",
       "      <th>client_id_median</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_id_mean</th>\n",
       "      <th>product_id_median</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_id_mean</th>\n",
       "      <th>route_id_median</th>\n",
       "      <th>sales_channel</th>\n",
       "      <th>sales_channel_mean</th>\n",
       "      <th>sales_channel_median</th>\n",
       "      <th>sales_depo</th>\n",
       "      <th>sales_depo_mean</th>\n",
       "      <th>sales_depo_median</th>\n",
       "      <th>week_num</th>\n",
       "      <th>week_num_mean</th>\n",
       "      <th>week_num_median</th>\n",
       "      <th>rand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>198780</td>\n",
       "      <td>8.566820</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35651</td>\n",
       "      <td>6.676974</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3301</td>\n",
       "      <td>18.730287</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15.159744</td>\n",
       "      <td>5</td>\n",
       "      <td>1110</td>\n",
       "      <td>15.904455</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.955922</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>886295</td>\n",
       "      <td>5.181818</td>\n",
       "      <td>6.0</td>\n",
       "      <td>47336</td>\n",
       "      <td>23.236511</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3301</td>\n",
       "      <td>18.730287</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15.159744</td>\n",
       "      <td>5</td>\n",
       "      <td>1110</td>\n",
       "      <td>15.904455</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.955922</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1603500</td>\n",
       "      <td>4.336364</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1240</td>\n",
       "      <td>5.725000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3301</td>\n",
       "      <td>18.730287</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15.159744</td>\n",
       "      <td>5</td>\n",
       "      <td>1110</td>\n",
       "      <td>15.904455</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.955922</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1914789</td>\n",
       "      <td>4.263158</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1240</td>\n",
       "      <td>5.725000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3301</td>\n",
       "      <td>18.730287</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15.159744</td>\n",
       "      <td>5</td>\n",
       "      <td>1110</td>\n",
       "      <td>15.904455</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.955922</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50720</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48077</td>\n",
       "      <td>3.098225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3302</td>\n",
       "      <td>21.278614</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15.159744</td>\n",
       "      <td>5</td>\n",
       "      <td>1110</td>\n",
       "      <td>15.904455</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.955922</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adjusted_demand  client_id  client_id_mean  client_id_median  product_id  \\\n",
       "0               23     198780        8.566820               6.0       35651   \n",
       "1                3     886295        5.181818               6.0       47336   \n",
       "2                5    1603500        4.336364               3.5        1240   \n",
       "3                5    1914789        4.263158               4.0        1240   \n",
       "4               10      50720        8.250000               8.0       48077   \n",
       "\n",
       "   product_id_mean  product_id_median  route_id  route_id_mean  \\\n",
       "0         6.676974                5.0      3301      18.730287   \n",
       "1        23.236511               10.0      3301      18.730287   \n",
       "2         5.725000                4.0      3301      18.730287   \n",
       "3         5.725000                4.0      3301      18.730287   \n",
       "4         3.098225                2.0      3302      21.278614   \n",
       "\n",
       "   route_id_median  sales_channel  sales_channel_mean  sales_channel_median  \\\n",
       "0              5.0              7           15.159744                     5   \n",
       "1              5.0              7           15.159744                     5   \n",
       "2              5.0              7           15.159744                     5   \n",
       "3              5.0              7           15.159744                     5   \n",
       "4              6.0              7           15.159744                     5   \n",
       "\n",
       "   sales_depo  sales_depo_mean  sales_depo_median  week_num  week_num_mean  \\\n",
       "0        1110        15.904455                5.0         3       6.955922   \n",
       "1        1110        15.904455                5.0         3       6.955922   \n",
       "2        1110        15.904455                5.0         3       6.955922   \n",
       "3        1110        15.904455                5.0         3       6.955922   \n",
       "4        1110        15.904455                5.0         3       6.955922   \n",
       "\n",
       "   week_num_median  rand  \n",
       "0                3     0  \n",
       "1                3     0  \n",
       "2                3     0  \n",
       "3                3     0  \n",
       "4                3     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "con = sqlite3.connect('/tmp/train_test_data.sqlite3')\n",
    "try:\n",
    "    # Set up the table\n",
    "    pandas.io.sql.to_sql(train_X.head(1), 'train_data', con=con, if_exists='replace', index=False)\n",
    "    iterr = iter(train_X.iterrows())\n",
    "    next(iterr)\n",
    "    collector = []\n",
    "    for _, row in tqdm.tqdm(iterr, total=train_X.shape[0]):\n",
    "        collector.append(row.values)\n",
    "        if len(collector) > 100000:\n",
    "            insert_term = ','.join('?' * row.shape[0])\n",
    "            con.executemany('insert into train_data values (%s)' % insert_term, collector)\n",
    "            collector = []\n",
    "    if collector:\n",
    "        insert_term = ','.join('?' * row.shape[0])\n",
    "        con.executemany('insert into train_data values (%s)' % insert_term, collector)\n",
    "    con.commit()\n",
    "finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "con = sqlite3.connect('/tmp/data.sqlite3')\n",
    "total = 20815581\n",
    "test_data = None\n",
    "chunksize = int(5e6)\n",
    "try:\n",
    "    data_iter = pandas.read_sql('''\n",
    "        SELECT week_num,\n",
    "               sales_depo,\n",
    "               sales_channel,\n",
    "               route_id,\n",
    "               client_id,\n",
    "               product_id,\n",
    "               adjusted_demand,\n",
    "               rand\n",
    "          FROM data \n",
    "         WHERE adjusted_demand is not null \n",
    "               AND week_num >= 8''', con=con, chunksize=chunksize)\n",
    "    for f in tqdm.tqdm(data_iter, total=1+total//chunksize):\n",
    "        # This halves the memory use :(\n",
    "        for col in f:\n",
    "            if f[col].dtype == np.int64:\n",
    "                f[col] = f[col].astype(np.int32)\n",
    "        if test_data is None:\n",
    "            test_data = f\n",
    "        else:\n",
    "            test_data = pandas.concat([test_data, f])\n",
    "finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_series = {'adjusted_demand': test_data.adjusted_demand}\n",
    "for col in tqdm.tqdm(admissible_cols):\n",
    "    mean_est, median_est = estimators[col].predict(test_data)\n",
    "    test_series[col + '_mean'] = mean_est\n",
    "    test_series[col + '_median'] = median_est\n",
    "    test_series[col] = test_data[col]\n",
    "    \n",
    "test_X = pandas.DataFrame(test_series)\n",
    "test_X['rand'] = test_data.rand\n",
    "test_X['week_num'] = test_data.week_num\n",
    "test_X['adjusted_demand'] = test_data.adjusted_demand\n",
    "\n",
    "#del test_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "con = sqlite3.connect('/tmp/train_test_data.sqlite3')\n",
    "try:\n",
    "    # Set up the table\n",
    "    pandas.io.sql.to_sql(test_X.head(1), 'test_data', con=con, if_exists='replace', index=False)\n",
    "    iterr = iter(test_X.iterrows())\n",
    "    next(iterr)\n",
    "    collector = []\n",
    "    for _, row in tqdm.tqdm(iterr, total=test_X.shape[0]):\n",
    "        collector.append(row.values)\n",
    "        if len(collector) > 100000:\n",
    "            insert_term = ','.join('?' * row.shape[0])\n",
    "            con.executemany('insert into test_data values (%s)' % insert_term, collector)\n",
    "            collector = []\n",
    "    if collector:\n",
    "        insert_term = ','.join('?' * row.shape[0])\n",
    "        con.executemany('insert into test_data values (%s)' % insert_term, collector)\n",
    "    con.commit()\n",
    "finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "con = sqlite3.connect('/tmp/data.sqlite3')\n",
    "total = 20815581\n",
    "test_data = None\n",
    "chunksize = int(5e6)\n",
    "try:\n",
    "    data_iter = pandas.read_sql('''\n",
    "        SELECT id,\n",
    "               week_num,\n",
    "               sales_depo,\n",
    "               sales_channel,\n",
    "               route_id,\n",
    "               client_id,\n",
    "               product_id,\n",
    "               adjusted_demand,\n",
    "               rand\n",
    "          FROM data \n",
    "         WHERE adjusted_demand is null''', con=con, chunksize=chunksize)\n",
    "    for f in tqdm.tqdm(data_iter, total=1+total//chunksize):\n",
    "        # This halves the memory use :(\n",
    "        for col in f:\n",
    "            if f[col].dtype == np.int64:\n",
    "                f[col] = f[col].astype(np.int32)\n",
    "        if test_data is None:\n",
    "            test_data = f\n",
    "        else:\n",
    "            test_data = pandas.concat([test_data, f])\n",
    "finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_series = {'adjusted_demand': test_data.adjusted_demand}\n",
    "for col in tqdm.tqdm(admissible_cols):\n",
    "    mean_est, median_est = estimators[col].predict(test_data)\n",
    "    test_series[col + '_mean'] = mean_est\n",
    "    test_series[col + '_median'] = median_est\n",
    "    test_series[col] = test_data[col]\n",
    "    \n",
    "test_X = pandas.DataFrame(test_series)\n",
    "test_X['rand'] = test_data.rand\n",
    "test_X['id'] = test_data.id\n",
    "test_X['week_num'] = test_data.week_num\n",
    "test_X['adjusted_demand'] = test_data.adjusted_demand\n",
    "\n",
    "del test_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "con = sqlite3.connect('/tmp/train_test_data.sqlite3')\n",
    "try:\n",
    "    # Set up the table\n",
    "    pandas.io.sql.to_sql(test_X.head(1), 'true_test_data', con=con, if_exists='replace', index=False)\n",
    "    iterr = iter(test_X.iterrows())\n",
    "    next(iterr)\n",
    "    collector = []\n",
    "    for _, row in tqdm.tqdm(iterr, total=test_X.shape[0]):\n",
    "        collector.append(row.values)\n",
    "        if len(collector) > 100000:\n",
    "            insert_term = ','.join('?' * row.shape[0])\n",
    "            con.executemany('insert into true_test_data values (%s)' % insert_term, collector)\n",
    "            collector = []\n",
    "    if collector:\n",
    "        insert_term = ','.join('?' * row.shape[0])\n",
    "        con.executemany('insert into true_test_data values (%s)' % insert_term, collector)\n",
    "    con.commit()\n",
    "finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
